\section{Threads und Prozesse}
Prozesse sind die Ausführung eines Programmes auf dem Prozessor. Jedoch kann ein Prozessor maximal einen Prozess gleichzeitig ausführen. Um Verwirrung zu beseitigen möchte ich darauf hinweisen, dass selbst moderne Prozessoren nicht in der Lage sind mehrere Prozesse auszuführen. Diese ``Illusion'' wird erzeugt, da ein Prozessor(Bauteil) mehrere Kerne hat. Diese Kerne sind die eigentlichen Prozessoren. In Zukunft werde ich den Begriff Kerne nutzen um die Unterscheidung zu erleichtern. Um trotzdem mehrere Prozesse gleichzeitig zu bearbeiten, werden den einzelnen Kernen die Prozesse für nur wenige Millisekunden zugeordnet. Diese nennt man auch Virtuelle Threads. Jeder Virtuelle Thread kann einem realem Kern zugeordnet werden. Jedoch wird nicht jeder Prozess gleich lange einem Kern zugeordnet. Die Prozesse konkurrieren um ihre Zeit. Denn schließlich soll mein Computerspiel nicht die gleiche Zeit bekommen, wie meine Stoppuhr-App. Dieser Wechsel zwischen den einzelnen Prozessen nennt man auch Kontextwechsel. Der Kontext des Kerns ändert sich demnach.

\begin{figure}[h]
    \centering
    \begin{tikzpicture}[auto, thick, node distance=2cm, >=triangle 45]
        \draw
        node at(0,0)[name=start1]{}
        node [sum, name=VThread1, right of=start1]{$V_1$}
        node [sum, name=VThread2, right of=VThread1]{$V_2$}
        node [sum, name=VThread3, right of=VThread2]{$V_3$}
        node [sum, name=VThread4, right of=VThread3]{$V_4$}
        node [sum, name=VThread5, right of=VThread4]{$V_5$}
        node [sum, name=VThread6, right of=VThread5]{$V_6$}
        node [sum, name=VThread7, right of=VThread6]{$V_7$}
        node [sum, name=VThread8, right of=VThread7]{$V_8$};
        \draw
        node at(1.7,-3)[name=start2]{}
        node [block, name=Kern1, right of=start2]{$K_1$}
        node [block, name=Kern2, right of=Kern1]{$K_2$}
        node [block, name=Kern3, right of=Kern2]{$K_3$}
        node [block, name=Kern4, right of=Kern3]{$K_4$};
        \draw[->](VThread1) -- node{} (Kern1.north);
        \draw[->](VThread3) -- node{} (Kern2.north);
        \draw[->](VThread4) -- node{} (Kern3.north);
        \draw[->](VThread7) -- node{} (Kern4.north);
    \end{tikzpicture}
    \caption{Aufteilung von Virtuellen Threads auf Kernel}
\end{figure}

\subsection{Aufbau von Prozessen}

Prozesse müssen noch ein wenig mehr als nur ein Stück Quelltext besitzen, um aktiv zu werden. Generell kann man sagen, dass Prozesse aus 7 Elementen bestehen.
Diese nennt man Prozesskontext. Innerhalb des Prozesskontextes gibt es noch den Hardwarekontext. Er besteht aus folgendem:
\begin{itemize}
    \setlength\itemsep{0pt}
    \item Das auszuführende Programm
    \item Die Daten des Programms: umfasst unter anderen die globalen Variablen
    \item Einem Stack: ein Stack funktioniert nach dem push und pop Verfahren und speichert die lokalen Variablen für einen schnelleren Zugriff
    \item Kernelstack: umfasst die Systemaufrufe des Prozesses
          \begin{itemize}
              \item CPU Register: kann in den meisten Fällen nur ein Befehl speichern (64bit Prozessor = 64bits im Register)
              \item MMU Register: verwaltet den Zugriff auf den Arbeitsspeicher
          \end{itemize}
\end{itemize}

Da ein Prozess viele Kontextwechsel durchleben wird, muss das Betriebssystem bestimmte Register speichern. Dazu gehört aus dem Hardwarekontext:

\begin{itemize}
    \setlength\itemsep{0pt}
    \item Instruction Pointer - die Speicheradresse des nächsten Befehls
    \item Instruction Register - der aktuelle Befehl
    \item Stackpointer - speichert das Ende des Stacks
    \item Basepointer - Speicheradresse des aktuellen Elements im Stack
    \item Akkumulator - speichert Ergebnisse der ALU
\end{itemize}

Dies sind die wichtigsten Informationen, um die Rechenoperationen weiterführen zu können. Das Betriebssystem braucht noch weitere Informationen über einen Prozess. Sie werden auch Systemkontext genannt. Die wichtigsten davon sind:

\begin{itemize}
    \setlength\itemsep{0pt}
    \item Ort in der Prozesstabelle
    \item PID - Prozessnummer
    \item Prozesszustand
    \item Priorität
    \item Eltern- oder Kindprozesse
    \item Zugriffsrechte - Linux: -20 bis 19
    \item Erlaubte Ressourcenmengen - bsp. Maximaler RAM Verbrauch
    \item Verwendete Dateien - um zu verhindern, dass mehre Prozesse an einer Datei arbeiten
    \item Zugeordnete Geräte - Maus, Tastatur, ...
\end{itemize}

Mithilfe der Prozesstabelle kann das Betriebssystem die einzelnen Prozesse speichern. In dieser werden Prozesskontrollblöcke gespeichert, welche den Hardwarekontext und Systemkontext beinhalten. Bei einem Kontextwechsel wird der Prozesskontext aus der Prozesstabelle wieder hergestellt.

\newpage

\subsection{Verwalten der Prozesse}

Jedes Betriebssystem muss einen Weg haben, um effektiv die Kontextwechsel der Prozesse durchführen zu können. Dazu wird in den meisten Fällen ein Warteschlangen System, siehe Abbildung \ref{Warteschlange Prozesse}, verwendet. Auch hat ein Prozess deutlich mehr Zustände in einem modernen Betriebssystem als nur \textit{untätig} und \textit{rechnend}. Dazu wird heutzutage meistens das Prozessmodell wie in Abbildung \ref{Prozessmodell} oder eine modifizierte Variante verwendet. Linux als Beispiel verwendet ein \textit{8-Zustands Prozessmodell}, welches das Modell mit einem \textit{kernel rechnend} Zustand erweitert.

\begin{figure}[h]
    \centering
    \input{images/Threads/Warteschlange.tex}
    \caption{Warteschlangensystem\protect\footnotemark}
    \label{Warteschlange Prozesse}
\end{figure}
\footnotetext{Grafik in Anlehnung an \cite[Seite 154]{BetriebssystemeKompakt}}
\begin{figure}[h]
    \centering
    \input{images/Threads/Prozessmodell.tex}
    \caption{7-Zustands Prozessmodell\protect\footnote{eine fußnote}}
    \label{Prozessmodell}
\end{figure}

\newpage
\footnotetext{Grafik in Anlehnung an \cite[Seite 156]{BetriebssystemeKompakt}}

Wie in der Einleitung schon angesprochen sind die Zustände \textit{bereit} und \textit{rechnend} die wichtigsten Zustände. Mit diesen alleine könnte ein Betriebssystem funktionieren. In diesem System gibt es nur eine Warteschlange, in der sich alle Prozesse des Zustandes \textit{bereit} befinden. Idealer Weise implementiert der \textit{Scheduler}\footnote{Programm zum Managen der Warteschlangen.} einen Algorithmus, welcher die Priorität der Prozesse berücksichtigt. Wie schon erwähnt muss sich der \textit{Dispatcher}\footnote{Programm zum Ausführen der Prozesswechsel.} um noch weitere Zustände kümmern. Diese und ihre Beziehungen sind in Grafik \ref{Prozessmodell} zu finden. Zwei davon wären \textit{neu} und \textit{beendet}. Diese sind für eine größere Flexibilität nützlich. Mit dem \textit{beendet}-Zustand, können Informationen nachträglich von einem fertigen Prozess aufgerufen werden. Der Zustand \textit{neu} hat die gemeinsame Funktion mit dem \textit{beendet}-Zustand Ressourcen zu sparen.\newline
Ein entscheidender Fehler ist es anzunehmen, dass alle Prozesse jederzeit arbeiten wollen. So könnte ein Programm auf eine Tastatur Eingabe oder andere Ereignisse warten. Um diese Funktionalität bereitzustellen, gibt es den Zustand \textit{blockiert}. In diesen wechselt ein Prozess nach dem berechnen und kann aus diesen sich wieder in die Warteschlange der \textit{bereiten}-Prozesse einordnen. In Grafik \ref{Warteschlange Prozesse} werden unterschiedliche Warteschlangen für unterschiedliche Ereignisse erzeugt. Dieses Vorgehen hat den Vorteil gegenüber einer einzelnen ``blockiert-Warteschlange'', dass häufig genutzte Events wie Tastenanschläge nicht von seltenen Events beeinträchtigt werden.\newline
Da es sehr schnell zu vielen Prozessen kommen kann, wird mit den Zuständen \textit{blockiert suspendiert} und \textit{bereit suspendiert} eine Möglichkeit geschaffen, selten genutzte Prozesse aus dem Arbeitsspeicher in den Massenspeicher\footnote{Spezielle Partitionen auf einer Festplatte. Auch \textit{swap} genannt.} zu verschieben. Wie die Namen schon implizieren werden Prozesse in den Zuständen \textit{blockiert} und \textit{bereit} jeweils suspendiert und aktiviert. Für zusätzliche Geschwindigkeit können Prozesse selbst im suspendierten Zustand auf Ereignisse reagieren und von \textit{blockiert suspendiert} in \textit{bereit suspendiert} wechseln. Es gibt demnach ein zweites \captionref{Warteschlange Prozesse} für die suspendierten Prozesse. Dieses beinhaltet keinen ?Zugriff auf die CPU, sondern kann die Prozesse maximal aktivieren und in den Arbeitsspeicher verschieben. \cite{BetriebssystemeKompakt}

\newpage

\subsection{Funktionsweise des Schedulers}
Der \textit{Scheduler} ist ein sehr wichtiges und mächtiges Stück Quelltext. Es regelt alle anderen Prozesse eines Betriebssystems. Es kann sich die Frage gestellt werden, wie der \textit{Scheduler} ausgeführt wird. Ist er nur ein weiterer Prozess? Dies würde aber implizieren, dass er sich selber managen würde. Oder wird er auf einem eigenen CPU Kern ausgeführt? Aber Linux läuft doch auch auf einem einzelnem Kern. Die Antwort liegt in der Natur des Kernels.
\medskip
\newline
Der Kernel ist die niedrigste Instanz mit der höchsten Berechtigung in einem System. Nichts steht zwischen ihm und der CPU. Jedes Programm muss über den Kernel um arbeiten zu können. Der \textit{Scheduler} ist ein Teil des Kernels. Der Kernel ist jedoch kein einzelner Prozess, welcher immer läuft, sondern eine Art Bibliothek. Ein Programm wendet sich an den Kernel und nicht der Kernel an das Programm. Dementsprechend läuft der \textit{Scheduler} nicht dauerhaft, sondern wird extern getriggert. Der \textit{Scheduler} wird entweder von einem beendeten Prozess oder nach einer Zeitunterbrechung getriggert. Die Zeitunterbrechung wird dabei von der CPU durch den \textit{programmable interrupt timer (PIT)} erzeugt und im Kernel durch den \textit{timer interrupt handler} aufgefangen, welcher auch den \textit{Scheduler} startet. Es wird dabei zwischen einem \textit{ticked kernel} und \textit{tickless kernel} unterschieden. Bei dem \textit{ticked kernel} ist der Zeitintervall immer gleich, wogegen der des \textit{tickless kernels} dynamisch verändert werden kann.\cite{tickles:Love}
\bigskip
\newline
Der \textit{Scheduler} verwaltet die einzelnen Warteschlangen und entscheidet, wann ein Prozess auf die CPU zugreifen darf. Dabei ist es wichtig die beste Effizienz beizubehalten und trotzdem eine gute Verteilung der Prozesszeit zu ermöglichen. Denn Kontextwechsel sind aufwändig. Bei vielen kleinen Prozessen wird viel Zeit für das Speichern der Register und das Wiederherstellen eines Prozesses aus der \textit{Prozesstabelle} verwendet. Je länger ein Prozess arbeiten kann, desto effizienter wird die Zeit genutzt. Daher haben sich zwei grundlegende Konzepte des \textit{schedulings} gebildet. Diese Schedulingverfahren sind:
\begin{itemize}
    \item \textit{Nicht-präemptives Scheduling}. Bei diesem hat ein Prozess, bis zu seiner Fertigstellung, volle Kontrolle über die CPU. Der \textit{Scheduler} führt erst den Kontextwechsel nach dessen Vollendung aus. Es kann Situationen geben, bei denen ein Prozess sich nicht selber beendet. Beispielsweise durch eine Endlosschleife in der Programmierung oder der Entwickler setzt bei der Programmierung das \textit{Präemtive Scheduling} voraus.
    \item \textit{Präemtives Scheduling}. Dieses wird seit Windows 3.x und Mac OS8/9 verwendet. Dabei wird nicht auf die Vollendung eines Prozesses gewartet, sondern kann und wird in den meisten Fällen, der Prozess der CPU vor Beendung entzogen. Der Vorteil ist, dass viele weitere Prozesse ``gleichzeitig'' arbeiten können, ohne dass der Nutzer das ``Einfrieren'' anderer Prozesse erfährt. Der Nachteil dabei ist, dass die Kontextwechsel viel Zeit in Anspruch nehmen. Somit haben die Prozesse weniger Arbeitszeit und die gesamte Leistung der CPU sinkt etwas. Da die Vorteile der größeren Freiheit der leicht verringerten Leistung überwiegen, wird dieses Verfahren in den meisten modernen Betriebssystemen verwendet. \cite{BetriebssystemeKompakt}
\end{itemize}

Auf diesen zwei grundlegenden Systemen haben sich weitere \textit{Scheduling} Verfahren entwickelt, welche das Verwalten der Warteschlange implementieren. Um ein ideales System zu erschaffen, müssen bestimmte Punkte berücksichtigt werden. Es lassen sich nicht immer alle Kriterien miteinander vereinbaren und es ist dem Entwickler überlassen, welche er bevorzugt. Die Kriterien wären wie folgt: \cite{Scheduling:Williams}
\begin{itemize}
    \item Prozessor-Auslastung - die Prozessor-Auslastung sollte im Idealfall so hoch wie möglich sein, damit kein Befehlszyklus\footnote{Ein Befehlszyklus ist der kleinste Zeitintervall einer CPU. Befehle können unterschiedlich viele Befehlszyklen brauchen. Je kleiner der Befehlszyklus ist, desto höher ist die Hertz Anzahl einer CPU} verschwendet wird
    \item Antwortzeit - die Zeit, die vergeht, bis die erste Antwort eines Prozesses nach Anfrage ankommt
    \item Durchlaufzeit - die Zeit, die vergeht, bis ein Prozess nach Einreichung beendet ist
    \item Durchsatz - wie viele Prozesse in einem vorgegebenen Intervall beendet werden. Der Intervall kann je nach Anwendungsfall variieren
    \item Wartezeit - die Zeit, die ein Prozess in der bereit-Warteschlange verbringt, bis er zugriff auf die CPU bekommt
    \item Fairness - die Fairness eines Verfahren bestimmt, wie gut kleine und weniger priorisierte Prozesse eine Chance haben Prozesszeit zu erhalten
\end{itemize}

Im Folgenden werde ich zwei \textit{Scheduling} Verfahren vorstellen.
\newpage
\subsubsection{Completetely Fair Scheduling}
\textit{Completetely Fair Scheduling}\footnote{\textit{Completetely Fair Scheduling (CFS)} wurde 2007 das erste Mal von Ingo Molnar im Linux Kernel eingearbeitet.} ist, wie der Name schon impliziert, eine Form des \textit{Ideal Fair Scheduling}. Es besagt, dass versucht wird die Prozesse gleich lange Arbeiten zu lassen. In den Tabellen \ref{Fair Scheduling} sind vier Prozesse dargestellt. Alle haben die selbe Priorität. In dem Szenario hat jeder Zeit-Quant($Q_1$, $Q_2$, \dots) eine Zeitspanne von 4ms. In den ersten vier Quanten bekommt jeder Prozess 1ms. Ab $Q_4$ sind Prozess B und D abgeschlossen und A und C erhalten somit in $Q_5$ jeweils 2ms. Durch das Prinzip werden alle Prozesse gleich behandelt. \cite[Ab 1:35]{CFS:Rebeiro}
\begin{figure}[h]
    \centering
    \begin{tabular}{| l | l |}
        \hline
        Prozess & Ausführungszeit\\
        \hline
        A & 8ms\\
        \hline
        B & 4ms\\
        \hline
        C & 16ms\\
        \hline
        D & 4ms\\
        \hline
    \end{tabular}
    \begin{tabular}{| x{1em} | x{1em} | x{1em} | x{1em} | x{1em} | x{1em} | x{1em} | x{1em} | x{1em} |}
        \hline
        \rowcolor{black!10}
        & $Q_1$ & $Q_2$ & $Q_3$ & $Q_4$ & $Q_5$ & $Q_6$ & $Q_7$ & $Q_8$\\
        \hline
        \rowcolor{black!20}
        A & 1 & 2 & 3 & 4 & 6 & 8 & &\\
        \hline
        \rowcolor{black!10}
        B & 1 & 2 & 3 & 4 & & & &\\
        \hline
        \rowcolor{black!20}
        C & 1 & 2 & 3 & 4 & 6 & 8 & 12 & 16\\
        \hline
        \rowcolor{black!10}
        D & 1 & 2 & 3 & 4 & & & &\\
        \hline
    \end{tabular}
    \captionof{table}{\textit{Fair Scheduling (FS)}\protect\footnote{eine fußnote}}
    \label{Fair Scheduling}
\end{figure}
\footnotetext{Grafik in Anlehnung an \cite[Minute 1:35]{CFS:Rebeiro}}

Im CFS wird das Prinzip des FS nicht hauptsächlich mit Zeitscheiben gelöst. Es wird das Konzept der \textit{vruntime} eingebracht. \textit{Vruntime} bedeutet dabei, wie lange ein Prozessor bereits ausgeführt wurde. CFS berechnet weiterhin unterschiedliche Zeitscheiben für die PIT, jedoch werden diese zur Maximierung der Effizienz genutzt. Prozesse mit komplexen Rechnungen sind effizienter, wenn sie mehr Zeit ohne Kontextwechsel haben. Prozesse wie Tracker\footnote{Programm um etwas aufzuzeichnen (Bspw. Anzahl der Tastenanschläge)} schadet der Kontextwechsel nicht allzu sehr. Der \textit{Scheduler} addiert auf die alte \textit{vruntime} die Zeit $\Delta t$, die der Prozessor lief. Sollte der Prozess noch nicht abgeschlossen sein, wird die neue \textit{vruntime} in einen Rot-Schwarz Baum eingefügt. Ein Rot-Schwarz Baum ist ein Binärbaum, welcher eine selbst ausgleichende Natur besitzt. Somit beträgt die einfüge Laufzeit $\mathcal{O}(\log n)$. CFS wählt als nächsten Prozess, den mit der geringsten \textit{vruntime} aus. Dabei wird immer ein Pointer auf das kleinste Blatt gehalten, um mit einer Laufzeit von $\mathcal{O}(1)$ den Prozess mit der kleinsten \textit{vruntime} zu finden. Durch das Wählen der kleinsten \textit{vruntime} wird das Prinzip des \textit{Fair Schedulings} eingehalten. \cite[Ab 5:22]{CFS:Rebeiro}
\medskip
\newpage
Das Nutzen der \textit{vruntime} als zentralen Wert hat weitere Vorteile. So können die Prioritäten ohne Umwege eingearbeitet werden. Der CFS verwaltet in der \textit{vruntime} drei unterschiedliche \textit{Scheduling Policies}. \cite{LinuxDoc:Torvalds}
\begin{itemize}
    \item \textbf{SCHED\_NORMAL/SCHED\_OTHER} - die normale Regel für Prozesse
    \item \textbf{SCHED\_BATCH} - für Prozesse, die nicht interaktiv sind und den Arbeitsbereich des Nutzers nicht stören wollen
    \item \textbf{SCHED\_IDLE} - die niedrigste Regel für Prozesse und sie werden an wenigsten bevorzugt
\end{itemize}
SCHED\_NORMAL und SCHED\_BATCH sind zusätzlich von den \textit{nice} Werten abhängig. Die \textit{nice} Werte reichen von -20 bis 19 und repräsentieren die Priorität eines Prozesses. Je kleiner der \textit{nice} Wert, desto höher ist die Priorität\cite{Scheduler:Kerrisk}. Dabei ist der Unterschied linear. Die Verteilung des Prozessors auf zwei Prozesse mit \textit{nice} Werten von 11 und 12, wäre 55\% und 45\%. Bei Prozessen mit -4 und -5 bleibt die Verteilung gleich. Die neue \textit{vruntime} wird mit Formel \ref{calc_vruntime}\cite{LinuxKernel:Torvalds} berechnet.
\begin{align}
    \text{vruntime} \mathrel{+}= \text{delta\_exec} \cdot \frac{\text{weigth}}{\text{lw.weight}}
    \label{calc_vruntime}
\end{align}
Dabei ist \textit{weigth} mit 1024 oder \textit{nice\_0} definiert. \textit{lw.weigth} ist die Priorität als \textit{weigth}. Das kann aus dem Array in dem Listing \ref{core.c}\cite{LinuxKernel:Torvalds} entnommen werden.
\begin{figure}[h]
    \centering      
    \lstset{
    language=C,
    keywordstyle=\color{blue},
    commentstyle=\color{green},
    }
    \begin{tabular}{c}
        \begin{lstlisting}{Latexkernel core.c}
10886 const int sched_prio_to_weight[40] = {
10887 /* -20 */ 88761, 71755, 56483, 46273, 36291,
10888 /* -15 */ 29154, 23254, 18705, 14949, 11916,
10889 /* -10 */ 9548,  7620,  6100,  4904,  3906,
10890 /*  -5 */ 3121,  2501,  1991,  1586,  1277,
10891 /*   0 */ 1024,  820,   655,   526,   423,
10892 /*   5 */ 335,   272,   215,   172,   137,
10893 /*  10 */ 110,   87,    70,    56,    45,
10894 /*  15 */ 36,    29,    23,    18,    15,
10895 };
        \end{lstlisting}
    \end{tabular}
    \captionof{lstlisting}{Linuxkernel core.c{\footnotesize (v5.17-rc3)} \textit{nice} Werte als \textit{weigth}}
    \label{core.c}
\end{figure}
\newpage

\subsubsection{Round Robin}
Das Round Robin(RR) Verfahren ist weitverbreitet. Es wird in abgewandelter Form auch heutzutage in Windows verwendet.\cite{Windows:Lohmann} Das RR \textit{Scheduling} nutzt Zeitquanten. Diese Befinden sich meistens im ein- oder zweistelligen Millisekundenbereich. Jeder Prozess wird nacheinander für die Länge des Zeitquanten ausgeführt und danach dem Prozessor entzogen. Ist der Prozess früher beendet, wird ein neuer Zeitquant eingeleitet. Ist der Prozess nicht beendet, wird er wieder in die Warteschlange am Ende angehängt.\cite[Seite 176f.]{BetriebssystemeKompakt}\\
\begin{figure}[h]
    \centering
    \begin{tabular}{| l | l |}
        \hline
        Prozess & Ausführungszeit\\
        \hline
        \cellcolor{red!20}A & 30ms\\
        \hline
        \cellcolor{blue!20}B & 50ms\\
        \hline
        \cellcolor{green!20}C & 20ms\\
        \hline
        \cellcolor{black!20}D & 30ms\\
        \hline
    \end{tabular}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        \cellcolor{red!20} & \cellcolor{red!20} & \cellcolor{blue!20} & \cellcolor{blue!20} & \cellcolor{green!20} & \cellcolor{green!20} & \cellcolor{black!20} & \cellcolor{black!20} & \cellcolor{red!20} & \cellcolor{blue!20} & \cellcolor{blue!20} & \cellcolor{black!20} & \cellcolor{blue!20}\\
        \hline
        \multicolumn{1}{l}{} & \multicolumn{2}{c}{\tiny 20} & \multicolumn{2}{c}{\tiny 40} & \multicolumn{2}{c}{\tiny 60} & \multicolumn{2}{c}{\tiny 80} & \multicolumn{2}{c}{\tiny 100} & \multicolumn{2}{c}{\tiny 120}\\
    \end{tabular}
    \caption{Round Robin Beispiel}
    \label{RoundRobin}
\end{figure}

In \ref{RoundRobin} werden vier Prozesse in der vorgegebenen Reihenfolge abgearbeitet. Die Zeitquanten in dem Beispiel sind 20ms lang. Prozess C benötigt nur ein Zeitquanten und wird beendet. Prozesse A und D benötigen 1.5 Zeitquanten. Sie arbeiten beim zweiten Mal nur 10ms und der nächste Prozess kann nachrücken. Prozess B benötigt am meisten Zeit und wird dreimal ausgeführt. Erst beim dritten Mal kann er beendet werden.
\medskip
\newline
Das Round Robin Verfahren kann noch mit Prioritäten erweitert werden. Dieses werde ich am Beispiel des \textit{Schedulers} von Windows erklären. Windows verwendet ein prioritätengesteuertes \textit{Scheduling}\footnote{Die Prioritäten von Windows reichen dabei von 0 bis 31}. Das RR Verfahren wird dabei immer auf die selbe Priorität angewendet. Die höhere Priorität wird immer bevorzugt. Dazu wird für jede Priorität eine eigene Warteschlange angelegt. Um das Verhungern eines Prozesses zu verhindern, nutzt Windows noch variable Prioritäten. Bei den variablen Prioritäten hat Windows noch die Möglichkeit selber zu ermitteln welche Prozesse wichtiger sind.\cite[Folie 9-12]{Windows:Lohmann}
\medskip
\newline
Mit dem Round Robin Verfahren kann grundsätzlich eine faire Umgebung geschaffen werden. Werden jedoch Prioritäten ohne Variation bevorzugt, kann es zu einem unfairen System werden. Auch sind I\/O-lastige\footnote{I\/O = Input\/Output. Ein Prozess wartet z.B. auf eine Eingabe des Benutzers.} Prozesse benachteiligt. Sie benötigen selber nur wenig Ausführungszeit, müssten aber für das reibungslose Funktionieren häufiger Zugriff auf den Prozessor erhalten. Im Round Robin \textit{Scheduling} müssen sie warten, bis rechenintensive Prozesse den Zeitquanten vollständig verbrauchen, bevor sie wieder an der Reihe sind.

\subsection{Threads}\label{Threads}
In modernen Computer Systemen gibt es noch Threads neben Prozessen. Threads sind dabei deutlich häufiger vertreten als Prozesse. Auf meinem Computer laufen durchschnittlich 20x mehr Threads als Prozesse. Dies liegt daran, dass Threads als Prozess eines Prozesses gesehen werden. Ein Programm ist nur ein Prozess, kann aber viele eigene Threads besitzen. Die Funktionalität von Threads unterscheidet sich nicht viel von Prozessen. Sie werden im \textit{Scheduler} gleich behandelt und es gibt nur geringe Unterschiede bei dem Kontextwechsel.
\medskip
\newline
Threads haben jedoch ein paar Besonderheiten gegenüber Prozessen. Denn im Gegensatz zu Prozessen, welche unabhängig voneinander laufen, haben Threads diese Beschränkung nicht. Es liegt daran, dass Threads auf den Stack des Prozesses zugreifen können. Threads teilen sich somit die globalen Variablen des Prozesses, speichern aber eigene lokale Variablen im eigenen Stack. Aufgrund diesem Prinzip können mehrere Threads mit dem selben Quelltext arbeiten, ohne sich gegenseitig zu behindern.\cite{Threads:Williams}
\begin{figure}[h]
    \centering
    \input{images/Threads/ThreadinProzess.tex}
    \caption{Threads}
\end{figure}
\\Threads werden als Teil eines Prozesses betrachtet. Deswegen sind sie viel leichtgewichtiger und können schneller erstellt und beendet werden. Zusätzlich werden Threads in zwei Kategorien unterteilt.
\begin{itemize}
    \item \textbf{Nutzer Level Threads} werden mithilfe einer Thread-library implementiert und sind unabhängig von dem Betriebssystem. Infolge können Nutzer Level Threads auch auf einem System ohne unterstütztem Multiprozessing in Betrieb genommen werden. Außerdem ist das Management von vielen Threads schneller, da keine Systemaufrufe getätigt werden müssen.
    \item \textbf{Kernel Level Threads} werden vom Betriebssystem implementiert und auch von diesem verwaltet. Dadurch ergeben sich Vorteile, wie auch Nachteile. Ein Vorteil wäre, dass Prozesse mit einer hohen Thread Anzahl bevorzugt werden könnten. Der Nachteil ist, dass die Verwaltung auf Kernel Ebene deutlich intensiver ist. Auch muss für jeden Thread ein einzelner Kontrollblock erstellt werden. \cite{Threads:Dusey}
\end{itemize}
\subsection{Threads in Java}
In Java sind Threads auf dem Kernel Level implementiert. In Versionen vor 1.2(1998) gab es die so genannten grünen Threads. Diese waren Nutzer Level Threads und in der Java VM implementiert. Heutzutage nutzt Java Kernel Level Threads, welche den Vorteil haben die gesamte CPU zu nutzen. Ein Prozess mit mehreren Threads kann somit alle vorhandenen CPU Kerne benutzen. Im Modell der grünen Threads wurde dies über Umwege gelöst. So wurden die grünen Threads abwechselnd auf ein paar Kernel Level Threads verteilt, um mehrere Kerne nutzten zu können.\cite{Threads:Cox}
\subsubsection{Implementation in Java}
Threads werden in Java mithilfe der \textit{java.lang.Thread} Klasse verwirklicht. Es wird dabei zwischen zwei unterschiedlichen Implementierungen unterschieden.
\smallskip
\newline
\textbf{extends Thread:} Bei dieser Methode wird eine Klasse erstellt, welche die Thread Klasse erweitert. Der Vorteil dieses Vorgehens ist, dass alle Einstellungen innerhalb der neuen Klasse getätigt werden können.\cite{Java:Thread}
\lstset{
language=Java,
keywordstyle=\color{blue},
commentstyle=\color{green},
basicstyle=\linespread{0.8}\small,
}
\begin{figure}[h]
\begin{lstlisting}{extends Thread}
public class SimpleThread extends Thread {

    public SimpleThread(){
        super();
        //settings
        setPriority(Thread.NORM_PRIORITY);
    }

    @Override
    public void run(){
        System.out.println("Im Running");
    }

    public static void main(String[] args){
        SimpleThread t = new SimpleThread();
        t.start();
    }
}
\end{lstlisting}
\captionof{lstlisting}{mit Thread erweitern}
\end{figure}
\\Das Vorgehen hat seine Probleme. Denn es wird nicht die \textit{run()} Methode von Thread überschrieben, sondern die von Runnable, welches von Thread implementiert wird. Wenn die Thread Klasse erweitert wird, kann man keine weiteren Klassen erweitern. Um ein solches Problem zu lösen, kann auf die zweite Möglichkeit zurückgegriffen werden.
\smallskip
\newline
\textbf{implements Runnable:} Bei dieser Methode wird nicht ein selbständiger Thread erschaffen. Das Interface Runnable hat nur eine Methode - die \textit{run()} Methode.\cite{Java:Runnable} Um einen Thread zu starten, muss ein Thread Object erschaffen werden, welche im Konstruktor ein Object des interfaces Runnable erwartet.
\begin{figure}[h]
\begin{lstlisting}
public class SimpleRunnable implements Runnable{
    public SimpleRunnable(){

    }

    @Override
    public void run(){
        System.out.println("Im Running");
    }

    public static void main(String[] args){
        SimpleRunnable r = new SimpleRunnable();
        Thread t = new Thread(r);
        t.start();
    }
}
\end{lstlisting}
\captionof{lstlisting}{Runnable implementieren}
\end{figure}
\\Der Vorteil dieses Vorgehen ist, dass Runnable leichtgewichtiger ist und erst bei Ausführung ein Thread Object erschaffen wird. Auch ist die Separierung zwischen ``Aufgabe'' und ``Bearbeiter'' sinnvoll. Man erhält eine große Flexibilität. Es können zusätzlich Einstellungen an dem erschaffenen Thread Object vorgenommen werden. Die Methoden wie \textit{setPriority()} sind public.\cite{Java:Thread} Ein weiterer wichtiger Punkt ist, dass Runnables in einem Thread-Pool verwendet werden können.

\subsubsection{Thread-Pool}
Ein Thread-Pool ist wie eine zweite CPU nur in Software. Es gibt eine Warteschlange und eine festgelegte Anzahl an arbeitenden Threads. Der Unterschied ist, dass die Warteschlange nicht aus Threads besteht, sondern aus \textit{Runnables}. Diese werden auch nur ein einziges Mal ausgeführt und dabei nicht unterbrochen. Auch wird die Warteschlange chronologisch abgearbeitet. Ein Thread-Pool hat somit ein \textit{nicht-präemtives Scheduling}, welches mit dem \textit{first in first out} Verfahren arbeitet.\newpage
\begin{figure}[h]
    \include{images/Threads/ThreadPool.tex}
    \caption{Thread-Pool\protect\footnotemark}
    \label{Thread-Pool}
\end{figure}
\footnotetext{Grafik in Anlehnung an \url{https://en.wikipedia.org/wiki/Thread_pool}}
In einem Thread-Pool werden die Aufgaben als \textit{Runnable} Object verwaltet. Eine bestimmte Anzahl an Threads arbeiten und erhalten immer neue \textit{Runnables}. Durch dieses Verfahren, muss nicht für jede Aufgabe ein neuer Thread erstellt werden. Auch ist ein Thread-Pool effizienter. Wenn viel berechnet werden muss, ist es besser weniger aktive Threads zu benutzten. Würden alle Aufgaben gleichzeitig gestartet werden, müsste der \textit{System Scheduler} die Threads verwalten. Es würden somit viel mehr Kontextwechsel stattfinden, bis alle Aufgaben abgearbeitet sind. Daher ist eine optimale Größe eines Thread-Pools in der Größenordnung der vorhandenen Kerne.\cite{ThreadPool:Java}

\subsubsection{Threadsicherheit}\label{Threadsicherheit}
\begin{center}
    \textit{
        [...]That the concept [of thread safety] itself is completely vague and essentially means nothing more than ``behaves correctly in some situations''[...]
    } - Eric Lippert \cite{Threads:Lippert}
\end{center}

Wie Herr Lippert in seinem Artikel bereits klarstellt, ist Threadsicherheit kein besonders kleines Thema. Auch ist Threadsicherheit immer im Auge des Betrachters. Es kommt immer auf die Situation an. Ist etwas in diesem speziellen Szenario Thread sicher? Denn eine allumfangende Threadsicherheit kann in den meisten Fällen nicht erreicht werden. Darum werde ich mich auf einen wichtigen Bereich der Threadsicherheit beschränken.
\medskip
\newline
Wie in Kapitel \ref{Threads} beschrieben, haben Threads einen gemeinsamen globalen Speicher. Das Problem dessen tritt auf, wenn mehrere Threads gleichzeitig auf die selben Speicheradresse zugreifen. Ein simples Beispiel ist, dass erhöhen einer Zahl. Diese Situatuion tritt auch in meinem Programm, siehe Kapitel \ref{Programm}, auf. Dabei versuchen mehrere Threads den selben Integer zu erhöhen. Das Ergebnis ist, dass trotz 2000x erhöhen im Integer nur 1800 gespeichert ist. Um das Problem zu verstehen werde ich erklären, wie ein Integer erhöht wird.\\
Ein Integer wird nicht an seinem Speicherort geändert. Die Bytes werden erst in den Prozessor geladen und dann mit dem gewünschten Wert addiert. Der alte Wert wird mit dem neuen Wert aus dem Register überschrieben. Im Falle von vielen Threads fetcht\footnote{Deutsch: bringen - ein Programm ließt Daten.} sich ein Thread den Wert $W_1 = 500$. Thread zwei, welcher kurz nach Thread eins gestartet wurde, fetcht auch den Wert $W_2 = 500$. Beide addieren ihren Teil und erhalten $W_3 = 501$ und $W_4 = 501$. Beide Werte werden anschließend nacheinander auf den alten Wert geschrieben. Wurde somit der Wert zwei mal erhöht, ist im Ergebnis aber nur um eins gestiegen.\cite{ThreadInterference:Oracle}\\
Um solches Verhalten zu vermeiden, gibt es in Java das Schlüsselwort \textit{synchronized}. Es beschränkt den Zugriff auf eine Methode oder Quelltext-Abschnitt auf nur einen Thread. Alle anderen Threads müssen auf das Beenden des vorherigen warten. Das Beispiel würde als Threadsichere Version wie folgt aussehen: \cite{SynchronizedMethods:Oracle}
\begin{figure}[h]
    \begin{lstlisting}
public class ThreadSafe{

        int counter=0;

        public synchronized void increase(){
            counter++;
        }
}
    \end{lstlisting}
    \captionof{lstlisting}{synchronized in Java}
\end{figure}