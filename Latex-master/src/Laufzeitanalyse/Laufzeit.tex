\section{Laufzeitanalyse}
\subsection{Einleitung}
Um die Effizienz des Programms beurteilen zu können, werde ich die einzelnen Algorithmen betrachten. Dazu werde ich Das erstellen einer Datenbank, berechnen der durchschnittlichen Farbe, skalieren der Bilder und das berechnen der besten Bilder vergleichen. Der Test kann mit einer UI im Programm durchgeführt werden. Es wird ein Test mehrfach durchgeführt und bei jedem neuem Durchgang die Anzahl an Bildern erhöht. Das Testen kann mit generierten Bildern und mit zufälligen Bildern der Internetseite ``https://picsum.photos'' durchgeführt werden. Alle folgenden Tests werden mit zufälligen Bildern durchgeführt, da diese die echte Benutzung am besten Simulieren. Bei den Generierten Bildern sinken die Berechnungszeiten stark, da weniger Farbkomplexität gegeben ist. Bei jeder Simulation wird auch der benötigte Arbeitsspeicher gespeichert, da das Programm sehr Arbeitsspeicher intensiv werden kann. Die Laufzeit des Berechnen der durchschnittlichen Farbe, das erstellen einer Datenbank und das berechnen der besten Bilder ist Linear. Folglich ergibt sich die Laufzeitkomplexität von $s(n)$. Wobei $n$ die Anzahl der verwendeten Bilder ist. Die Größe der Bilder wurde nicht beachtet, da diese Allein durch die zweidimensionale Natur von Bildern eine Quadratische Laufzeit ergeben würden.
\begin{align}
    s(n) \in \mathcal{O}(n)
\end{align}
Die Laufzeit des Skalieren ist abhängig von dem genutzten Algorithmus.
\bigskip
\newline
Alle Tests wurden mit dem folgenden Computer durchgeführt.
\begin{figure}[h]
    \centering
    \begin{tabular}{| l | l |}
        \hline
        CPU             & \makecell[l]{\underline{AMD Ryzen 7 2700} \\ 8Core 16Threads 3,65GH}\\
        \hline
        Festplatte      & \makecell[l]{\underline{Corsair MP600 2T NVMe M.2 SSD} \\ Lesen: 3,4GB Schreiben: 3,2GB}\\
        \hline
        Arbeitsspeicher & \makecell[l]{\underline{GSkill 2x16GB} \\ Taktrate: 3,2GH}\\
        \hline
        JavaVM          & \makecell[l]{\underline{java 17 Runtime Enviroment} \\ Arg: -Xmx25G}\\
        \hline
    \end{tabular}
\end{figure}

\newpage
\subsection{Testungen}
\begin{figure}
    \centering
    \subfloat[\centering Datenbank]{
        \begin{tikzpicture}[scale = 0.85]
            \begin{axis}[tick label style={
                /pgf/number format/fixed,
                /pgf/number format/fixed zerofill,
                /pgf/number format/precision=1
            }, legend pos=north west, no markers, legend style={nodes={scale=0.7, transform shape}}]
                \addplot table [x=x, y=time, col sep=semicolon] {./images/Simulationen/Database_1.000x10.000.csv};
                \addlegendentry{Zeit in ns}
                \addplot table [x=x, y=ram, col sep=semicolon] {./images/Simulationen/Database_1.000x10.000.csv};
                \addlegendentry{Ram in Byte}
            \end{axis}
        \end{tikzpicture}
        \label{DatenbankGraph}
    }
    \subfloat[\centering durchschnittliche Farbe]{
        \begin{tikzpicture}[scale = 0.85]
            \begin{axis}[tick label style={
                /pgf/number format/fixed,
                /pgf/number format/fixed zerofill,
                /pgf/number format/precision=1
            }, legend pos=north west, no markers, legend style={nodes={scale=0.7, transform shape}}]
                \addplot table [x=x, y=time, col sep=semicolon] {./images/Simulationen/averageColor_500x50_500x500_Ultra.csv};
                \addlegendentry{Zeit in ns}
                \addplot table [x=x, y=ram, col sep=semicolon] {./images/Simulationen/averageColor_500x50_500x500_Ultra.csv};
                \addlegendentry{Ram in Byte}
            \end{axis}
        \end{tikzpicture}
        \label{DurchschnittlicheFarbeGraph}
    }
    \hspace{0mm}
    \subfloat[\centering skalieren der Bilder]{
        \begin{tikzpicture}[scale = 0.85]
            \begin{axis}[tick label style={
                /pgf/number format/fixed,
                /pgf/number format/fixed zerofill,
                /pgf/number format/precision=1
            }, legend pos=north west, no markers, legend style={nodes={scale=0.7, transform shape}}]
                \addplot table [x=x, y=time, col sep=semicolon] {./images/Simulationen/scalingImages.csv};
                \addlegendentry{Bilinear(ns)}
                \addplot table [x=x, y=time, col sep=semicolon] {./images/Simulationen/scalingImagesBikubisch.csv};
                \addlegendentry{Bikubisch(ns)}
                \addplot table [x=x, y=ram, col sep=semicolon] {./images/Simulationen/scalingImages.csv};
                \addlegendentry{Bilinear(Byte)}
                \addplot table [x=x, y=ram, col sep=semicolon] {./images/Simulationen/scalingImagesBikubisch.csv};
                \addlegendentry{Bikubisch(Byte)}
            \end{axis}
        \end{tikzpicture}
        \label{SkalierenGraph}
    }
    \subfloat[\centering berechnen der besten Bilder]{
        \begin{tikzpicture}[scale = 0.85]
            \begin{axis}[tick label style={
                /pgf/number format/fixed,
                /pgf/number format/fixed zerofill,
                /pgf/number format/precision=1
            }, legend pos=north west, no markers, legend style={nodes={scale=0.7, transform shape}}]
                \addplot table [x=x, y=time, col sep=semicolon] {./images/Simulationen/computation.csv};
                \addlegendentry{Zeit in ns}
                \addplot table [x=x, y=ram, col sep=semicolon] {./images/Simulationen/computation.csv};
                \addlegendentry{Ram in Byte}
            \end{axis}
        \end{tikzpicture}
        \label{BesteBilderGraph}
    }
    
    \caption[Laufzeit]{Vergleich Laufzeiten und Arbeitsspeicher}
\end{figure}
Test \ref{DatenbankGraph} wurde von $10000$ bis $10000000$ Bilder durchgeführt. Die Zeit erhöht sich um 1250ns pro Bild. Die Arbeitsspeichernutzung erhöht sich um 87Byte pro Bild. Die Arbeitsspeichernutzung ist dabei auch stark von der Länge des Speicherortes des Bildes abhängig.
\newline
Test \ref{DurchschnittlicheFarbeGraph} wurde von $1000$ bis $25000$ Bilder durchegführt. Die Bilder hatten eine größe von 500x500px. Die Laufzeit für ein Bild liegt bei 1,09ms. Für jedes weitere Bild werden 88kByte verbraucht. Beide Werte verhalten sicht linear zu der Anzahl der Bilder.
\newline
Das Skalieren der Bilder in \ref{SkalierenGraph} wurde jeweils mit einem Bilinearen Algorithmus und einem Bikubischen Algorithmus durchgeführt. Dazu wurden 500x500px große Bilder auf 100x70px scaliert. Der Test wurde mit $1000$ Bildern gestartet und mit $12500$ beendet. Es ist zu erkennen, dass nur ein geringer Laufzeitunterschied von $\Delta t = 4,2ms - 3,7ms = 0,5ms$ zwischen den beiden Algorithmen besteht. Dieser geringe unterschied kommt daher, dass beide Algorithmen sich sehr ähnlich verhalten. Der Unterscheid liegt lediglich bei der komplexeren Berechnung in dem Bikubischem Algorithmus, welche nur einen Teil der Laufzeit beansprucht. Der Arbeitsspeicherverbrauch ist bei beiden Algorithmen gleich und erreicht 136KB.
\newline
Der schnellste Process ist das berechnen der Bilder. Dies liegt an der zuvor erstellten Datenbank und ihrem sortiertem Aufbau. Dabei wird eine Laufzeit von 2,31ns pro Bild erreicht. Der Test wurde mit $5000000$ Bildern durchgeführt. Die Arbeitsspeichernutzung ist die selbe wie in Test \ref{DatenbankGraph}, da das berechnen der Bilder auch Datenbanken braucht.

\medskip

Als nächstes werde ich alle Algorithmen gemeinsam Testen. Dazu werde ich als Referenzbild ein 4890x3263px Bild\footnote{Bild von \url{https://media.jaguar.com/de-de/news/2020/11/jaguar-f-type-r-cabrio-siegt-bei-den-sport-auto-awards-2020}} verwenden. Ich werde die Datenbank nur einmal erstellen, da die Laufzeit von dieser sich nicht verändern wird. Bei jedem Test, wird das zu berechnete Bild um 3 skaliert. Es sollte demnach ein 14670x9789px Bild entstehen.

\begin{center}
    \begin{minipage}{10cm}
        \centering
        \begin{tabular}{| l | l | l |}
            \hline
            Test Typ & Spezifikationen & Zeit \\
            \hline
            Datenbank & \makecell[l]{Bilder: 500000 \\ Größe: 200x300} & 10 min 26 sek\\
            \hline
            & \makecell[l]{Multiplikator: 3\footnote{Das resultierende Bild wird drei mal größer sein.}\\ Max.: \qquad \quad \hspace{2pt} 50\footnote{Die maximale Anzahl, die ein Bild verwendet werden darf.} \\ Qualität: \quad \quad Ultra\footnote{Die beste Einstellung. Es werden bei der Analyse keine Pixel übersprungen und Bikubische Skalierung wird verwendet.}\\ \hline} & \\
            
            & \makecell[l]{Aufteilungen: 500x500} & 02 min 20 sek\\
            Bild erstellen & \makecell[l]{Aufteilungen: 700x700} & 04 min 03 sek\\
            & \makecell[l]{Aufteilungen: 999x999} & 21 min 38 sek\\
            \hline
        \end{tabular}
    \end{minipage}
\end{center}

Es ist zu erkennen, dass die Steigung von Test 1 auf Test 2 den Erwartungen entspricht. Die Sektoren  Anzahl hat sich verdoppelt, dementsprechend auch die Laufzeit. Bei dem Sprung von Test 2 auf Test 3 ist eine Vervierfachung anstelle einer erwarteten Verdopplung aufgetreten. Eine Erklärung für das Verhalten könnte die ansteigende Datenmenge, welche das Optimum des Test Computers überschreitet. Eine Version mit 999x999 Sektoren und einem Multiplikator von 6 kann unter folgendem Link jeweils mit 50\% Transparenz und ohne angesehen werden. Ich Empfehle einen Computer mit 16GB Arbeitsspeicher, um sich die Bilder anzusehen, da sie 1GB als PNG verbrauchen. \url{}